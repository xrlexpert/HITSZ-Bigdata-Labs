{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from category_encoders import MEstimateEncoder\n",
    "import optuna\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train path:\n",
    "train_path = '../data/train.csv'\n",
    "# test path:\n",
    "test_path = '../data/test.csv'\n",
    "# load train data:\n",
    "train = pd.read_csv(train_path, index_col='Id')\n",
    "test = pd.read_csv(test_path, index_col='Id')\n",
    "print(train.head())\n",
    "print('Train data contains {} rows and {} features'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "print(test.head())\n",
    "print('Test data contains {} rows and {} features'.format(test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat test and train data:\n",
    "all_data = pd.concat([train, test])\n",
    "all_data.tail(10)\n",
    "\n",
    "# Vsiualize the percentages of missing values per features:\n",
    "missing_values = pd.DataFrame({'Percentage' : (all_data.isnull().sum()/len(all_data)) * 100}, \n",
    "                              index=all_data.columns)\n",
    "missing_values = missing_values[missing_values['Percentage']>0].sort_values(\n",
    "    by='Percentage', \n",
    "    ascending=False)\n",
    "missing_values.drop(index='SalePrice', inplace=True)\n",
    "missing_values.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical and continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = train.select_dtypes(include=['object']).columns.tolist()\n",
    "continuous_features.remove('SalePrice')\n",
    "print('There are {} continuous features and {} categorical features'.format(len(continuous_features), len(categorical_features)))\n",
    "print('Continuous features: ', continuous_features)\n",
    "print('Categorical features: ', categorical_features)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating correlations :\n",
    "train_corr = train.select_dtypes(include=[np.number])\n",
    "# Calculating correlations:\n",
    "corr = train_corr.corr()\n",
    "# Sorting correlations with SalePrice:\n",
    "corr_sorted = corr['SalePrice'].abs().sort_values(ascending=False)\n",
    "corr_high = corr_sorted[corr_sorted>0.5].index\n",
    "# Subsetting correlations:\n",
    "corr = corr.loc[corr_high, corr_high]\n",
    "# Visualize the heatmap:\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "* preserve all the features\n",
    "* fill NA with median value\n",
    "* single XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "\n",
    "test_id = test['Id']\n",
    "\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "continuous_columns = train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "discret_columns = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in discret_columns:\n",
    "    train[col].fillna(-1,inplace=True)\n",
    "    test[col].fillna(-1,inplace=True)\n",
    "    res1 = train[col].value_counts().keys()\n",
    "    res2 = test[col].value_counts().keys()\n",
    "    res = list(set(res1).union(set(res2)))\n",
    "    mapping = dict(zip(res, range(len(res))))\n",
    "    print(f'{col}:{mapping}')\n",
    "    train[col] = train[col].map(mapping)\n",
    "    test[col] = test[col].map(mapping)\n",
    "\n",
    "train.to_csv('../data/train_pro.csv',index=False)\n",
    "test.to_csv('../data/test_pro.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(X, y, ratio=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    划分训练集和验证集\n",
    "    :param X: 特征\n",
    "    :param y: 标签\n",
    "    :param ratio: 训练集比例\n",
    "    :return: X_train, y_train, X_val, y_val\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n = X.shape[0]\n",
    "    y = y.astype(int)\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    X, y = X[indices], y[indices]\n",
    "    split = int(n * ratio)\n",
    "    X_train, y_train = X[:split], y[:split]\n",
    "    X_val, y_val = X[split:], y[split:]\n",
    "    return X_train, y_train, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    'ratio':0.8,\n",
    "    'seed':42\n",
    "}\n",
    "df = pd.read_csv('../data/train_pro.csv')\n",
    "data = df.values\n",
    "n = data.shape[0]\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "X_train, y_train, X_val, y_val = split_train_val(X, y, config.get('ratio'), seed=config.get('seed'))\n",
    "#choose the best model\n",
    "xgb_model = XGBRegressor(learning_rate=0.015,n_estimators=4750,max_depth=3,min_child_weight=0,subsample=0.7,colsample_bytree=0.4064,nthread=-1,scale_pos_weight=2,seed=42)\n",
    "xgb_model.fit(X_train,y_train, eval_set = [(X_val,y_val)])\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('../data/test_pro.csv')\n",
    "data_test = df_test.values\n",
    "X_test = data_test[:,1:]\n",
    "pred = xgb_model.predict(X_test)\n",
    "pred_train = xgb_model.predict(X_train)\n",
    "submission = pd.DataFrame({\n",
    "    'Id': data_test[:,0].astype(int),  # Assuming test set has an 'Id' column\n",
    "    'SalePrice': pred # Replace 'Target' with the name of your target column\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('../res/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试并提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test = test.values\n",
    "X_test = data_test[:,1:]\n",
    "pred = xgb_model.predict(X_test)\n",
    "pred_train = xgb_model.predict(X_train)\n",
    "submission = pd.DataFrame({\n",
    "    'Id': data_test[:,0].astype(int),  # Assuming test set has an 'Id' column\n",
    "    'SalePrice': pred # Replace 'Target' with the name of your target column\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('../res/submission_baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
